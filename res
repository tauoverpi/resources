#topic:actor
#medium:paper
Actor Model of Computation: Scalable Robust Information Systems
The Actor Model is a mathematical theory that treats “Actors” as the
universal primitives of digital computation.  The model has been used
both as a framework for a theoretical understanding of concurrency, and as
the theoretical basis for several practical implementations of concurrent
systems. The advent of massive concurrency through client-cloud computing
and many-core computer architectures has galvanized interest in the Actor Model
^
@https://arxiv.org/pdf/1008.1459.pdf
#topic:actor
#medium:paper
Formalizing common sense reasoning for scalable inconsistency-robust information integration using Direct LogicTM Reasoning and the Actor Model
People use common sense in their interactions with large information systems.
This common sense needs to be formalized so that it can be used by computer
systems. Unfortunately, previous formalizations have been inadequate. For
example, classical logic is not safe for use with pervasively inconsistent
information. The goal is to develop a standard foundation for reasoning in
large-scale Internet applications (including sense making for natural
language)
^
@https://arxiv.org/pdf/0812.4852.pdf
#topic:bigraphs
#topic:category theory
#medium:paper
Bigraphical reactive systems: basic theory
A notion of bigraph is proposed as the basis for a model of mobile
interaction. A bigraph consists of two independent structures: a topograph
representing locality and a monograph representing connectivity. Bigraphs
are equipped with reaction rules to form bigraphical reactive systems (BRSs),
which include versions of the -calculus and the ambient calculus. Bigraphs are
shown to be a special case of a more abstract notion, wide reactive systems
(WRSs), not assuming any particular graphical or other structure but equipped
with a notion of width, which expresses that agents, contexts and reactions
may all be widely distributed entities
^
@https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-523.pdf
#topic:mbus
#topic:wireless mbus
#topic:security
#medium:paper
Wireless M-Bus Security Whitepaper
This work aims to analyse the security of the Meter Bus as specified
in the relevant International organisation for Standardization (ISO)
documentation. M-Bus has its roots in the heat metering industries and
was continuously adopted to fit more complex applications. M-Bus is the
communication bus of choice of several meter manufacturers and its applications
span from drive-by wireless meter reading over to meter-to-meter and mesh
networking to meter-to-collector communication. M-Bus implementations support
different media types such as power line carrier (PLC) or twisted-pair
bus. To avoid the wiring efforts at the distribution level, utilities,
metering companies and manufacturers tend to more frequently choose wireless
protocols for communication. Accordingly, the analysis will mainly concentrate
on M-Bus wireless based communication – wM-Bus
^
@https://www.compass-security.com/fileadmin/Datein/Research/Praesentationen/blackhat_2013_wmbus_security_whitepaper.pdf
#topic:fpga
#topic:neural network
#topic:machine learning
#medium:paper
FPGA Implementations of Neural Networks
During the 1980s and early 1990s there was significant work in the design
and implementation of hardware neurocomputers. Nevertheless, most of
these efforts may be judged to have been unsuccessful: at no time have
have hardware neurocomputers been in wide use. This lack of success may be
largely attributed to the fact that earlier work was almost entirely aimed
at developing custom neurocomputers, based on ASIC technology, but for such
niche areas this technology was never sufficiently developed or competitive
enough to justify large-scale adoption. On the other hand, gate-arrays of
the period mentioned were never large enough nor fast enough for serious
artificial-neuralnetwork (ANN) applications. But technology has now improved:
the capacity and performance of current FPGAs are such that they present
a much more realistic alternative. Consequently neurocomputers based on
FPGAs are now a much more practical proposition than they have been in the
past. This book summarizes some work towards this goal and consists of 12
papers that were selected, after review, from a number of submissions.
^
@http://lab.fs.uni-lj.si/lasin/wp/IMIT_files/neural/doc/Omondi2006.pdf
#topic:fpga
#topic:neural network
#topic:machine learning
#medium:paper
A General Neural Network Hardware Architecture on FPGA
Field Programmable Gate Arrays (FPGAs) plays an increasingly important
role in data sampling and processing industries due to its highly
parallel architecture, low power consumption, and flexibility in custom
algorithms. Especially, in the artificial intelligence field, for training and
implement the neural networks and machine learning algorithms, high energy
efficiency hardware implement and massively parallel computing capacity are
heavily demanded. Therefore, many global companies have applied FPGAs into
AI and Machine learning fields such as autonomous driving and Automatic
Spoken Language Recognition (Baidu) [1] [2] and Bing search (Microsoft)
[3]. Considering the FPGAs great potential in these fields, we tend to
implement a general neural network hardware architecture on XILINX ZU9CG
System On Chip (SOC) platform [4], which contains abundant hardware resource
and powerful processing capacity. The general neural network architecture
on the FPGA SOC platform can perform forward and backward algorithms in deep
neural networks (DNN) with high performance and easily be adjusted according
to the type and scale of the neural networks.
^
@https://arxiv.org/ftp/arxiv/papers/1711/1711.05860.pdf
#topic:file system
#medium:paper
TagFS: A simple tag-based filesystem
TagFS is a simple yet effective tag-based filesystem. Instead of organizing files and documents in
a strict hierarchy (like traditional filesystems), TagFS allows users to assign descriptive attributes
(called tags) to files and subsequently locate those files by searching for tags of interest.
^
@https://web.mit.edu/6.033/2011/wwwdocs/writing-samples/sbezek_dp1.pdf
#topic:optimisation
#topic:neural network
#topic:genetic algorithms
#topic:differential evolution
#topic:bee swarm algorithm
#topic:ant colony optimisation
#medium:book
Clever Algorithms: Nature-Inspired Programming Recipes
Implementing an Artificial Intelligence algorithm is difficult. Algorithm
descriptions may be incomplete, inconsistent, and distributed across a
number of papers, chapters and even websites. This can result in varied
interpretations of algorithms, undue attrition of algorithms, and ultimately
bad science. This book is an effort to address these issues by providing
a handbook of algorithmic recipes drawn from the fields of Metaheuristics,
Biologically Inspired Computation and Computational Intelligence, described in
a complete, consistent, and centralized manner. These standardized descriptions
were carefully designed to be accessible, usable, and understandable. Most
of the algorithms described were originally inspired by biological and
natural systems, such as the adaptive capabilities of genetic evolution
and the acquired immune system, and the foraging behaviors of birds, bees,
ants and bacteria. An encyclopedic algorithm reference, this book is intended
for research scientists, engineers, students, and interested amateurs. Each
algorithm description provides a working code example in the Ruby Programming
Language.
^
@https://raw.githubusercontent.com/clever-algorithms/CleverAlgorithms/master/release/clever_algorithms.pdf
#topic:category theory
#topic:haskell
#topic:c++
#topic:template metaprogramming
#topic:type system
#author:Bartosz Milewski
Category Theory for Programmers
For some time now I’ve been floating the idea of writing a book about
category theory that would be targeted at programmers. Mind you, not computer
scientists but programmers — engineers rather than scientists. I know
this sounds crazy and I am properly scared. I can’t deny that there is
a huge gap between science and engineering because I have worked on both
sides of the divide. But I’ve always felt a very strong compulsion to
explain things. I have tremendous admiration for Richard Feynman who was
the master of simple explanations. I know I’m no Feynman, but I will try
my best. I’m starting by publishing this preface — which is supposed
to motivate the reader to learn category theory — in hopes of starting a
discussion and soliciting feedback.
^
@https://github.com/hmemcpy/milewski-ctfp-pdf/releases/download/v1.3.0/category-theory-for-programmers.pdf
#topic:category theory
#topic:version control
#author:Samuel Mimram
#author:Cinzia Di Giusto
#medium:paper
A Categorical Theory of Patches
When working with distant collaborators on the same documents, one often
uses a version control system, which is a program tracking the history of
files and helping importing modifications brought by others as patches. The
implementation of such a system requires to handle lots of situations depending
on the operations performed by users on files, and it is thus difficult to
ensure that all the corner cases have been correctly addressed. Here, instead
of verifying the implementation of such a system, we adopt a complementary
approach: we introduce a theoretical model, which is defined abstractly
by the universal property that it should satisfy, and work out a concrete
description of it. We begin by defining a category of files and patches,
where the operation of merging the effect of two coinitial patches is defined
by pushout. Since two patches can be incompatible, such a pushout does not
necessarily exist in the category, which raises the question of which is the
correct category to represent and manipulate files in conflicting state. We
provide an answer by investigating the free completion of the category of files
under finite colimits, and give an explicit description of this category:
its objects are finite sets labeled by lines equipped with a transitive
relation and morphisms are partial functions respecting labeling and relations.
^
@https://arxiv.org/pdf/1311.3903
#topic:algorithm
#author:Eugene W. Myers
#medium:paper
An O(ND) Difference Algorithm and Its Variations∗
The problems of finding a longest common subsequence of two sequences A
and B and a shortest edit script for transforming A into B have long been
known to be dual problems. In this paper, they are shown to be equivalent to
finding a shortest/longest path in an edit graph. Using this perspective,
a simple O(ND) time and space algorithm is developed where N is the sum of
the lengths of A and B and D is the size of the minimum edit script for A
and B. The algorithm performs well when differences are small (sequences are
similar) and is consequently fast in typical applications. The algorithm is
shown to have O(N + D^2) expected-time performance under a basic stochastic
model. A refinement of the algorithm requires only O(N) space, and the use
of suffix trees leads to an O(NlgN + D^2) time variation
^
@http://www.xmailserver.org/diff2.pdf
#topic:sorting
#author:Sergei Bespamyatnikh
#author:Michael Segal
#medium:paper
Enumerating Longest Increasing Subsequences and Patience Sorting (2000)
In this paper we present three algorithms that solve three combinatorial
optimization problems related to each other. One of them is the patience
sorting game, invented as a practical method of sorting real decks of
cards. The second problem is computing the longest monotone increasing
subsequence of the given sequence of n positive integers in the range 1; : :
: ; n. The third problem is to enumerate all the longest monotone increasing
subsequences of the given permutation.
^
@http://www.ii.uni.wroc.pl/~lorys/IPL/article76-1-1.pdf
#topic:single static assignment
#topic:compiler
#topic:compiler optimisation
#author:Lori Carter
#author:Beth Simon
#author:Brad Calder
#author:Larry Carter
#author:Jeanne Ferrante
Predicated Static Single Assignment
Increases in instruction level parallelism are needed to exploit the potential
parallelism available in future wide issue architectures. Predicated execution
is an architectural mechanism that increases instruction level parallelism
by removing branches and allowing simultaneous execution of multiple paths
of control, only committing instructions from the correct path. In order
for the compiler to expose such parallelism, traditional compiler data-flow
analysis needs to be extended to predicated code.  In this paper, we present
Predicated Static Single Assignment (PSSA) to enable aggressive predicated
optimization and instruction scheduling. PSSA removes false dependences by
exploiting renaming and information about the multiple control paths. We
demonstrate the usefulness of PSSA for Predicated Speculation and Control
Height Reduction. These two predicated code optimizations used during
instruction scheduling reduce the dependence length of the critical paths
through a predicated region. Our results show that using PSSA to enable
speculation and control height reduction reduces execution time from 10%
to 58%.
^
@http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.18.7756&rep=rep1&type=pdf
#topic:single static assignment
#topic:compiler
#topic:compiler optimisation
Static Single Assignment Book

^
@http://ssabook.gforge.inria.fr/latest/book.pdf
#topic:neural network
#topic:auto-encoding
#author:Diederik P. Kingma
#author:Max Welling
Auto-Encoding Variational Bayes
How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets
and, under some mild differentiability conditions, even works in the
intractable case. Our contributions is two-fold. First, we show that a
reparameterization of the variational lower bound yields a lower bound
estimator that can be straightforwardly optimized using standard stochastic
gradient methods. Second, we show that for i.i.d. datasets with continuous
latent variables per datapoint, posterior inference can be made especially
efficient by fitting an approximate inference model (also called a recognition
model) to the intractable posterior using the proposed lower bound estimator.
Theoretical advantages are reflected in experimental results.
^
@https://arxiv.org/pdf/1312.6114.pdf
#author:Thomas N. Kipf
#author:Max Welling
Variational Graph Auto-Encoders
We introduce the variational graph auto-encoder (VGAE), a framework for
unsupervised learning on graph-structured data based on the variational
auto-encoder (VAE). This model makes use of latent variables and is capable
of learning interpretable latent representations for undirected graphs. We
demonstrate this model using a graph convolutional network (GCN) encoder and
a simple inner product decoder. Our model achieves competitive results on a
link prediction task in citation networks. In contrast to most existing models
for unsupervised learning on graph-structured data and link prediction, our
model can naturally incorporate node features, which significantly improves
predictive performance on a number of benchmark datasets.
^
@https://arxiv.org/pdf/1611.07308.pdf
#author:Carl Doersch
Tutorial on Variational Autoencoders
In just three years, Variational Autoencoders (VAEs) have emerged as one
of the most popular approaches to unsupervised learning of complicated
distributions. VAEs are appealing because they are built on top of standard
function approximators (neural networks), and can be trained with stochastic
gradient descent. VAEs have already shown promise in generating many kinds
of complicated data, including handwritten digits, faces, house numbers,
CIFAR images, physical models of scenes, segmentation, and predicting the
future from static images. This tutorial introduces the intuitions behind
VAEs, explains the mathematics behind them, and describes some empirical
behavior. No prior knowledge of variational Bayesian methods is assumed.
^
@https://arxiv.org/pdf/1606.05908.pdf
#author:Ronald Yu
A Tutorial on VAEs: From Bayes' Rule to Lossless Compression
The Variational Auto-Encoder (VAE) is a simple, efficient, and popular
deep maximum likelihood model. Though usage of VAEs is widespread, the
derivation of the VAE is not as widely understood. In this tutorial, we will
provide an overview of the VAE and a tour through various derivations and
interpretations of the VAE objective. From a probabilistic standpoint, we will
examine the VAE through the lens of Bayes' Rule, importance sampling, and the
change-of-variables formula. From an information theoretic standpoint, we will
examine the VAE through the lens of lossless compression and transmission
through a noisy channel. We will then identify two common misconceptions
over the VAE formulation and their practical consequences. Finally, we will
visualize the capabilities and limitations of VAEs using a code example
(with an accompanying Jupyter notebook) on toy 2D data.
^
@https://arxiv.org/pdf/2006.10273.pdf
#topic:signed distance field
#author:Chris Green
Improved Alpha-Tested Magnification for Vector Textures and Special Effects
A simple and efficient method is presented which allows improved rendering
of glyphs composed of curved and linear elements. A distance field is
generated from a high resolution image, and then stored into a channel of
a lower-resolution texture. In the simplest case, this texture can then be
rendered simply by using the alphatesting and alpha-thresholding feature of
modern GPUs, without a custom shader. This allows the technique to be used
on even the lowest-end 3D graphics hardware.  With the use of programmable
shading, the technique is extended to perform various special effect
renderings, including soft edges, outlining, drop shadows, multi-colored
images, and sharp corners.
^
@https://steamcdn-a.akamaihd.net/apps/valve/2007/SIGGRAPH2007_AlphaTestedMagnification.pdf
#topic:signed distance field
#author:Yue Jiang
#author:Dantong Ji
#author:Zhizhong Han
#author:Matthias Zwicker
SDFDiff: Differentiable Rendering of Signed Distance Fields for 3D Shape Optimization
We propose SDFDiff, a novel approach for image-based shape optimization using
differentiable rendering of 3D shapes represented by signed distance functions
(SDF).  Compared to other representations, SDFs have the advantage that
they can represent shapes with arbitrary topology, and that they guarantee
watertight surfaces. We apply our approach to the problem of multi-view 3D
reconstruction, where we achieve high reconstruction quality and can capture
complex topology of 3D objects. In addition, we employ a multi-resolution
strategy to obtain a robust optimization algorithm. We further demonstrate
that our SDF-based differentiable renderer can be integrated with deep
learning models, which opens up options for learning approaches on 3D objects
without 3D supervision. In particular, we apply our method to single-view
3D reconstruction and achieve state-of-the-art results.
^
@http://www.cs.umd.edu/~yuejiang/papers/SDFDiff.pdf
#topic:signed distance field
#topic:multi-channel signed distance field
#author:Viktor Chlumsk´
Shape Decomposition for Multi-channel Distance Fields
This work explores the possible improvements to a popular text rendering
technique widely used in 3D applications and video games. It proposes a
universal and efficient method of constructing a multi-channel distance
field for vector-based shapes, such as font glyphs, and describes its usage
in rendering with improved fidelity.
^
@https://github.com/Chlumsky/msdfgen/files/3050967/thesis.pdf
#topic:neural network
#author:Jianwen Xie
#author:Ruiqi Gao
#author:Zilong Zheng
#author:Song-Chun Zhu
#author:Ying Nian Wu
Learning Dynamic Generator Model by Alternating Back-Propagation Through Time
This paper studies the dynamic generator model for spatialtemporal processes
such as dynamic textures and action sequences in video data. In this model,
each time frame of the video sequence is generated by a generator model,
which is a non-linear transformation of a latent state vector, where the
non-linear transformation is parametrized by a top-down neural network. The
sequence of latent state vectors follows a non-linear auto-regressive model,
where the state vector of the next frame is a non-linear transformation of the
state vector of the current frame as well as an independent noise vector that
provides randomness in the transition. The non-linear transformation of this
transition model can be parametrized by a feedforward neural network. We show
that this model can be learned by an alternating back-propagation through time
algorithm that iteratively samples the noise vectors and updates the parameters
in the transition model and the generator model. We show that our training
method can learn realistic models for dynamic textures and action patterns.
^
@http://www.stat.ucla.edu/~jxie/DynamicGenerator/DynamicGenerator_file/doc/DynamicGenerator.pdf
#topic:neural network
#topic:cellular neural network
#author:N H Wulff
#author:J A Hertz t
Learning Cellular Automaton Dynamics with Neural Networks
We have trained networks of E - II units with short-range connections
to simulate simple cellular automata that exhibit complex or chaotic
behaviour. Three levels of learning are possible (in decreasing order of
difficulty): learning the underlying automaton rule, learning asymptotic
dynamical behaviour, and learning to extrapolate the training history. The
levels of learning achieved with and without weight sharing for different
automata provide new insight into their dynamics.
^
@https://papers.nips.cc/paper/703-learning-cellular-automaton-dynamics-with-neural-networks.pdf
#topic:neural network
#topic:cellular neural network
#author:Paolo Arena
#author:Luigi Fortuna
Cellular neural networks: from chaos generation to compexity modelling.

^
@https://www.researchgate.net/profile/Paolo_Arena2/publication/221165625_Cellular_neural_networks_from_chaos_generation_to_compexity_modelling/links/0a85e539fe2db469ce000000/Cellular-neural-networks-from-chaos-generation-to-compexity-modelling.pdf?origin=publication_detail
#topic:cellular automata
#author:Maria Vittoria Avolio
#author:Alessia Errera
#author:Valeria Lupiano
#author:Paolo Mazzanti
#author:Salvatore Di Gregorio
VALANCA: A Cellular Automata Model for Simulating Snow Avalanches
Numerical modelling is a major challenge in the prevention of hazards related
to the occurrence of catastrophic phenomena. Cellular Automata methods were
developed for modelling large scale (extended for kilometres) dangerous surface
flows of different nature such as lava flows, pyroclastic flows, debris
flows, rock avalanches, etc. This paper presents VALANCA, a first version
of a Cellular Automata model, developed for the simulations of dense snow
avalanches. VALANCA is largely based on the most advanced models developed
for flow-like landslides, and adopts some innovations such as outflows
characterized by the position of mass centre and explicit velocity. First
simulations of welldocumented snow avalanches occurred in the Davos region,
Switzerland (i.e. the 2006 Rüchitobel and the 2006 Gotschnawang snow
avalanches) show a satisfying agreement concerning the avalanche path, snow
cover erosion depth, deposit thickness and areal distribution. Furthermore,
preliminary simulations of the Gotschnawang snow-avalanche, by considering
the presence of mitigation structures, were performed.
^
@https://www.nhazca.it/wp-content/uploads/2020/06/VALANCA_2017.pdf
#topic:neural network
#topic:associative neural network
Neural Associative Memories
Neural associative memories (NAM) are neural network models consisting of
neuronlike and synapse-like elements. At any given point in time the state of
the neural network is given by the vector of neural activities, it is called
the activity pattern. Neurons update their activity values based on the inputs
they receive (over the synapses). In the simplest neural network models the
input-output function of a neuron is the identitiy function or a threshold
operation. Note that in the latter case the neural activity state is binary:
active or inactive. Information to be processed by the neural network is
represented by activity patterns (for instance, the representation of a tree
can an activity pattern where active neurons display a tree's picture). Thus,
activity patterns are the representations of the elements processed in the
network. A representation is called sparse if the ratio between active and
inactive neurons is small.
^
@https://courses.cit.cornell.edu/bionb330/readings/Associative%20Memories.pdf
#topic:neural network
#topic:associative neural network
Auto-associative Memory: The First Step in Solving Cocktail Party Problem
One of the most interesting and challenging problems in the area of Artificial
Intelligence is solving the Cocktail Party problem. This is the task of
attending to one speaker among several competing speakers and being able
to switch the attention from one speaker to another at any given time. Human
brain is remarkably efficient in solving this problem. There have been numerous
attempts to emulating this ability in machines. Independent Component Analysis
(ICA) and Blind Source Separation (BSS) are two of the most popular solutions
to this problem but they both fail to generate similar results as human brain
does. They are also very computationally expensive which makes them incapable
of producing results in real-time. Moreover, they generally require at least
two microphones to converge but as we know human brain can also work with
one ear covered. This is evident from the fact that covering one ear does
not make attending to one speaker in a cocktail party any harder.
^
@http://cs229.stanford.edu/proj2013/Youssefi-AutoassociativeMemory.pdf
#topic:cellular automata
#topic:physarum
#author:Jeff Jones
#author:Andrew Adamatzky
Emergence of Self-Organized Amoeboid Movement in a Multi-Agent Approximation of Physarum polycephalum
The giant single-celled slime mould Physarum polycephalum exhibits complex
morphological adaptation and amoeboid movement as it forages for food
and may be seen as a minimal example of complex robotic behaviour. Swarm
computation has previously been used to explore how spatiotemporal complexity
can emerge from, and be distributed within, simple component parts and their
interactions. Using a particle based swarm approach we explore the question
of how to generate collective amoeboid movement from simple non-oscillatory
component parts in a model of P.  polycephalum. The model collective behaves
as a cohesive and deformable virtual material, approximating the local
coupling within the plasmodium matrix. The collective generates de-novo and
complex oscillatory patterns from simple local interactions. The origin
of this motor behaviour is distributed within the collective rendering
is morphologically adaptive, amenable to external influence, and robust to
simulated environmental insult. We show how to gain external influence over the
collective movement by simulated chemo-attraction (pulling towards nutrient
stimuli) and simulated light irradiation hazards (pushing from stimuli). The
amorphous and distributed properties of the collective are demonstrated by
cleaving it into two independent entities and fusing two separate entities
to form a single device, thus enabling it to traverse narrow, separate or
tortuous paths. We conclude by summarising the contribution of the model to
swarm based robotics and soft-bodied modular robotics and discuss the future
potential of such material approaches to the field.
^
@https://arxiv.org/ftp/arxiv/papers/1212/1212.0023.pdf
#topic:casual commutative arrows
#topic:category theory
#topic:pure functional programming
#author:Jeremy Yallop
#author:Hai Liu
Causal Commutative Arrows Revisited
Causal commutative arrows (CCA) extend arrows with additional constructs and
laws that make them suitable for modelling domains such as functional reactive
programming, differential equations and synchronous dataflow. Earlier work
has revealed that a syntactic transformation of CCA computations into normal
form can result in significant performance improvements, sometimes increasing
the speed of programs by orders of magnitude. In this work we reformulate
the normalization as a type class instance and derive optimized observation
functions via a specialization to stream transformers to demonstrate that
the same dramatic improvements can be achieved without leaving the language.
^
@https://www.cl.cam.ac.uk/~jdy22/papers/causal-commutative-arrows-revisited.pdf
#topic:neural network
#topic:generative adversarial network
#author:Ian J. Goodfellow
#author:Jean Pouget-Abadie
#author:Mehdi Mirza
#author:Bing Xu
#author:David Warde-Farley
#author:Sherjil Ozair
#author:Aaron Courville
#author:Yoshua Bengio
Generative Adversarial Nets
We propose a new framework for estimating generative models via an adversarial
process, in which we simultaneously train two models: a generative model
G that captures the data distribution, and a discriminative model D that
estimates the probability that a sample came from the training data rather
than G. The training procedure for G is to maximize the probability of D
making a mistake. This framework corresponds to a minimax two-player game. In
the space of arbitrary functions G and D, a unique solution exists, with G
recovering the training data distribution and D equal to 1 2 everywhere. In
the case where G and D are defined by multilayer perceptrons, the entire
system can be trained with backpropagation.  There is no need for any Markov
chains or unrolled approximate inference networks during either training or
generation of samples. Experiments demonstrate the potential of the framework
through qualitative and quantitative evaluation of the generated samples.
^
@https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf
#topic:automata
#topic:compression
#author:Takahiro Ota
#author:Hiroyoshi Morita
Relationship between Antidictionary Automata and Compacted Substring Automata
There are two efficient static data compression algorithms called
an antidictionary coding and a lossless data compression via substring
enumeration coding. We prove that both of the encoders are isomorphic.
^
@http://ita.ucsd.edu/workshop/13/files/paper/paper_3113.pdf
#topic:emergence
#topic:cellular automata
An Emergent Approach to Game Design – Development and Play
Player enjoyment is the single-most important goal of games. Games that
are not enjoyable are not bought or played. Within games, enjoyment of the
gameplay hinges on the game world. However, game worlds are often static and
highly scripted, which leads to restricted and shallow gameplay that can
detract from player enjoyment. It is possible that player enjoyment could
be improved by the creation of more flexible game worlds that give players
more freedom and control. One way to create more flexible game worlds is
through the use of an emergent approach to designing game worlds. This thesis
investigates an emergent approach to designing game worlds, as well as the
issues, considerations and implications for game players and developers.
The research reported in this thesis consisted of three main components. The
first component involved conducting a focus group and questionnaire with
players to identify the aspects of current game worlds that affect their
enjoyment. The second component of the research involved investigating an
emergent approach to designing game worlds, in which the Emergent Games
Engine Technology (EmerGEnT) system was developed. The test-bed for the
EmerGEnT system was a strategy game world that was developed using a 3D
games engine, the Auran Jet. The EmerGEnT system consists of three main
components: the environment, objects and agents. The third component of the
research involved evaluating the EmerGEnT system against a set of criteria for
player enjoyment in games, which allowed the system’s role in facilitating
player enjoyment to be defined.  In the player-centred studies, it was found
that players are dissatisfied with the static, inconsistent and unrealistic
elements of current games and that they desire more interactivity, realism
and control. The development and testing of the EmerGEnT system showed that
an emergent game world design, based on cellular automata, can v facilitate
emergent behaviour in a limited domain. The domain modelled by the EmerGEnT
system was heat, fire, rain, fluid flow, pressure and explosions in a
strategy game world. The EmerGEnT system displayed advantages relating to
its ability to dynamically determine and accommodate the specific state of
the game world due to the underlying properties of the cells, objects and
agents. It also provided a model for emergent game worlds, which allowed
more complexity than emergent objects alone. Finally, the evaluation of
enjoyment revealed that incorporating an emergent game world (such as the
EmerGEnT system) into a game could improve player enjoyment in terms of
concentration, challenge, player skills, control and feedback by allowing
more intuitive, consistent and emergent interactions with the game world.
The implications of this research are that cellular automata can facilitate
emergence in games, at least in a limited domain. Also, emergence in games
has the potential to enhance player enjoyment in areas where current game
worlds are weak. Finally, the EmerGEnT system serves as a proof of concept
of using emergence in games, provides a model for simulating environmental
systems in games and was used to identify core issues and considerations
for future development and research of emergent game worlds.
^
@https://www.cp.eng.chula.ac.th/~vishnu/gameResearch/Sweetser_Thesis.pdf
